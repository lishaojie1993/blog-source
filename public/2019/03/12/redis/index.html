<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="分布式缓存-Redis"><meta name="keywords" content="分布式,redis"><meta name="author" content="lishaojie"><meta name="copyright" content="lishaojie"><title>分布式缓存-Redis | 李少杰のBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><link rel="alternate" href="/atom.xml" title="李少杰のBlog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#redis单线程模型原理剖析？"><span class="toc-number">1.</span> <span class="toc-text">redis单线程模型原理剖析？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis为什么这么快？"><span class="toc-number">2.</span> <span class="toc-text">redis为什么这么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用redis有什么缺点？"><span class="toc-number">3.</span> <span class="toc-text">使用redis有什么缺点？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis支持的数据类型和使用场景"><span class="toc-number">4.</span> <span class="toc-text">redis支持的数据类型和使用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redis的过期策略有哪些"><span class="toc-number">5.</span> <span class="toc-text">redis的过期策略有哪些</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#怎么保证redis的高并发-amp-高可用？"><span class="toc-number">6.</span> <span class="toc-text">怎么保证redis的高并发&amp;高可用？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#redis的主从复制"><span class="toc-number">6.1.</span> <span class="toc-text">redis的主从复制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#主从复制的核心原理"><span class="toc-number">6.1.1.</span> <span class="toc-text">主从复制的核心原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#主从复制的断点续传"><span class="toc-number">6.1.2.</span> <span class="toc-text">主从复制的断点续传</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#无磁盘化复制"><span class="toc-number">6.1.3.</span> <span class="toc-text">无磁盘化复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#过期key处理"><span class="toc-number">6.1.4.</span> <span class="toc-text">过期key处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#redis的心跳检测机制"><span class="toc-number">6.1.5.</span> <span class="toc-text">redis的心跳检测机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#redis的持久化"><span class="toc-number">6.1.6.</span> <span class="toc-text">redis的持久化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis的哨兵机制"><span class="toc-number">6.2.</span> <span class="toc-text">redis的哨兵机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#哨兵的核心知识"><span class="toc-number">6.2.1.</span> <span class="toc-text">哨兵的核心知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sdown和odown转换机制？"><span class="toc-number">6.2.2.</span> <span class="toc-text">sdown和odown转换机制？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#哨兵和slave集群的自动发现机制"><span class="toc-number">6.2.3.</span> <span class="toc-text">哨兵和slave集群的自动发现机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#slave-master选举算法"><span class="toc-number">6.2.4.</span> <span class="toc-text">slave-master选举算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#slave配置的自动纠正"><span class="toc-number">6.2.5.</span> <span class="toc-text">slave配置的自动纠正</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#quorum和majority"><span class="toc-number">6.2.6.</span> <span class="toc-text">quorum和majority</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#configuration-epoch"><span class="toc-number">6.2.7.</span> <span class="toc-text">configuration epoch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#configuration传播"><span class="toc-number">6.2.8.</span> <span class="toc-text">configuration传播</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#异步复制和集群脑裂导致数据丢失"><span class="toc-number">7.</span> <span class="toc-text">异步复制和集群脑裂导致数据丢失</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分布式集群-redis-cluster"><span class="toc-number">8.</span> <span class="toc-text">分布式集群-redis cluster</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#分布式数据存储的核心算法"><span class="toc-number">8.1.</span> <span class="toc-text">分布式数据存储的核心算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#最老土的hash算法和弊端"><span class="toc-number">8.1.1.</span> <span class="toc-text">最老土的hash算法和弊端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#一致性hash算法-自动缓存迁移"><span class="toc-number">8.1.2.</span> <span class="toc-text">一致性hash算法(自动缓存迁移)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#一致性hash算法-虚拟节点"><span class="toc-number">8.1.3.</span> <span class="toc-text">一致性hash算法+虚拟节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hash-slot算法"><span class="toc-number">8.1.4.</span> <span class="toc-text">hash slot算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis集群模式的工作原理"><span class="toc-number">8.2.</span> <span class="toc-text">redis集群模式的工作原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#节点间的内部通信机制"><span class="toc-number">8.2.1.</span> <span class="toc-text">节点间的内部通信机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#高性能与主备切换原理"><span class="toc-number">8.2.2.</span> <span class="toc-text">高性能与主备切换原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#缓存雪崩、缓存穿透、缓存击穿"><span class="toc-number">9.</span> <span class="toc-text">缓存雪崩、缓存穿透、缓存击穿</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存雪崩"><span class="toc-number">9.1.</span> <span class="toc-text">缓存雪崩</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#造成缓存雪崩的原因"><span class="toc-number">9.1.1.</span> <span class="toc-text">造成缓存雪崩的原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#如何预防缓存雪崩？"><span class="toc-number">9.1.2.</span> <span class="toc-text">如何预防缓存雪崩？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#缓存雪崩了如何恢复？"><span class="toc-number">9.1.3.</span> <span class="toc-text">缓存雪崩了如何恢复？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存穿透"><span class="toc-number">9.2.</span> <span class="toc-text">缓存穿透</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#造成缓存穿透的原因"><span class="toc-number">9.2.1.</span> <span class="toc-text">造成缓存穿透的原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#如何预防缓存穿透？"><span class="toc-number">9.2.2.</span> <span class="toc-text">如何预防缓存穿透？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存击穿"><span class="toc-number">9.3.</span> <span class="toc-text">缓存击穿</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#如何预防缓存击穿？"><span class="toc-number">9.4.</span> <span class="toc-text">如何预防缓存击穿？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何保证缓存与数据库的双写一致性"><span class="toc-number">10.</span> <span class="toc-text">如何保证缓存与数据库的双写一致性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#先删缓存，再更新数据库"><span class="toc-number">10.1.</span> <span class="toc-text">先删缓存，再更新数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#高并发场景下的数据不一致"><span class="toc-number">10.2.</span> <span class="toc-text">高并发场景下的数据不一致</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#问题描述"><span class="toc-number">10.2.1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案"><span class="toc-number">10.2.2.</span> <span class="toc-text">解决方案</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决方案需要注意的问题"><span class="toc-number">10.2.3.</span> <span class="toc-text">解决方案需要注意的问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何保证redis并发竞争的数据一致性"><span class="toc-number">11.</span> <span class="toc-text">如何保证redis并发竞争的数据一致性</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">lishaojie</div><div class="author-info__description text-center">Melody</div><div class="follow-button"><a href="https://github.com/lishaojie1993">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">28</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">39</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">6</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">淘宝链接</div><a class="author-info-links__name text-center" href="https://item.taobao.com/item.htm?spm=a1z10.1-c.w137644-18883948773.26.47a25effrGIzfB&amp;id=599185802394">优特家具</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://tva1.sinaimg.cn/large/006tNbRwgy1gash4k2x0uj31900u0b1g.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">李少杰のBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">分布式缓存-Redis</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-03-12</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Java/">Java</a><span class="post-meta__separator">|</span><i class="fa fa-comment-o post-meta__icon" aria-hidden="true"></i><a href="/2019/03/12/redis/#disqus_thread"><span class="disqus-comment-count" data-disqus-identifier="2019/03/12/redis/"></span></a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">8.5k</span><span class="post-meta__separator">|</span><span>Reading time: 26 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="redis单线程模型原理剖析？"><a href="#redis单线程模型原理剖析？" class="headerlink" title="redis单线程模型原理剖析？"></a>redis单线程模型原理剖析？</h2><p>redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器——file event handler。这个文件事件处理器是单线程的，所以redis才叫做单线程模型。redis采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。</p>
<h2 id="redis为什么这么快？"><a href="#redis为什么这么快？" class="headerlink" title="redis为什么这么快？"></a>redis为什么这么快？</h2><ol>
<li>纯内存操作。</li>
<li>核心是基于非阻塞的IO多路复用机制。</li>
<li>单线程——避免了多线程的频繁上下文切换问题。</li>
<li>Resp协议。<a id="more"></a></li>
</ol>
<h2 id="使用redis有什么缺点？"><a href="#使用redis有什么缺点？" class="headerlink" title="使用redis有什么缺点？"></a>使用redis有什么缺点？</h2><ul>
<li>缓存和数据库双写一致性问题</li>
<li>缓存雪崩、缓存击穿</li>
<li>缓存的并发竞争</li>
</ul>
<h2 id="redis支持的数据类型和使用场景"><a href="#redis支持的数据类型和使用场景" class="headerlink" title="redis支持的数据类型和使用场景"></a>redis支持的数据类型和使用场景</h2><ol>
<li><p>string</p>
<p>最基本的类型，普通的set和get，做简单的key-value缓存。</p>
</li>
<li><p>hash</p>
<p>类似map的一种结构，特别适合用存储对象，可以仅仅修改这个对象中的某个字段。</p>
</li>
<li><p>list</p>
<p>有序列表，这个是可以玩出很多花样的：</p>
<p>比如可以基于redis的list实现简单的高性能分页，类似于微博的那种一直下拉。</p>
<p>还可以搞个简单的消息队列，从list头进去，从list尾巴取出来。</p>
</li>
<li><p>set</p>
<p>无序集合，自动去重。</p>
<p>如果某个系统部署在多台机器上，可以基于redis实现全局的set去重。</p>
<p>还可以基于set玩交集，并集，差集的操作，比如利用交集，可以查看两个人的粉丝列表中的共同好友。</p>
</li>
<li><p>sorted set</p>
<p>有序集合，自动去重。</p>
<p>这个也可以玩很多花样，写数据进去的时候给一个分数，自动根据分数排序，可以自定义排序规则。</p>
<p>比如想根据数据的时间排序，那么在写入数据的时候把时间作为分数，这样就会按时间排序了。</p>
<p>排行榜：将每个用户以及对应的分数写入进去，会自动排序，可以查看前几名的结果。</p>
<p>zadd board 85 jack</p>
<p>zadd board 72 tom</p>
<p>zadd board 96 jerry</p>
<p>zrevrange board 0 2：可以查看前三名的排序结果</p>
<p>zrank board tom：返回3，意思是tom排名第3</p>
</li>
</ol>
<hr>
<h2 id="redis的过期策略有哪些"><a href="#redis的过期策略有哪些" class="headerlink" title="redis的过期策略有哪些"></a>redis的过期策略有哪些</h2><p><strong>定期删除+惰性删除</strong></p>
<p>所谓<strong>定期删除</strong>，指的是redis默认每隔100ms就随机抽取一些过期时间的key，检测是否过期，如果过期就删除。注意：这里redis不是遍历所有过期的key（CPU负载太高），而是随机抽取。</p>
<p>所谓<strong>惰性删除</strong>，指的是定期删除可能会导致很多过期的key到了时间也没被删除，所以在获取某个key的时候，redis会查一下这个key是否过期，如果过期了此时就会删除，不会返回结果。</p>
<p>产生问题：如果定期删除漏掉了很多过期key没删，惰性删除是用到的时候才删，如果过期了并且一直没用到就会导致有大量的过期key堆积，这时候就需要走<strong>内存淘汰机制</strong>了。</p>
<ol>
<li>no-enviction（驱逐）：禁止驱逐数据，再写入会报错。<strong>（默认，应该没人用）</strong></li>
<li>allkeys-lru：从数据集中挑选最近最少使用的数据淘汰。<strong>（推荐使用）</strong></li>
<li>allkeys-random：从数据集中任意选择数据淘汰。</li>
<li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。</li>
<li>volatile-ttl：从<code>已设置过期时间的</code>数据集中挑选<code>将要过期的</code>数据淘汰。</li>
<li>volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。</li>
</ol>
<hr>
<h2 id="怎么保证redis的高并发-amp-高可用？"><a href="#怎么保证redis的高并发-amp-高可用？" class="headerlink" title="怎么保证redis的高并发&amp;高可用？"></a>怎么保证redis的高并发&amp;高可用？</h2><p>redis高并发：采用<strong>主从架构</strong>，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒上10万的QPS。如果redis高并发的同时还需要容纳大量的数据：几十G甚至几百G的数据，这样的话就需要采用redis集群了，还能提供每秒几十万的读写并发。</p>
<p>redis高可用：如果做主从架构部署，其实加上<strong>哨兵</strong>就可以了，任何一个实例宕机，都会自动切换。</p>
<h3 id="redis的主从复制"><a href="#redis的主从复制" class="headerlink" title="redis的主从复制"></a>redis的主从复制</h3><p>主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑10+的<strong>读QPS</strong></p>
<p>首先考虑读写分离，做成主从架构，一主多从，主负责写，并且将数据同步到其他slave节点，从节点负责读，所有的读请求都走从节点。好处是可以水平扩容，就是说如果QPS再增加，只需要继续增加slave就可以了。 </p>
<h4 id="主从复制的核心原理"><a href="#主从复制的核心原理" class="headerlink" title="主从复制的核心原理"></a>主从复制的核心原理</h4><p>当启动一个slave的时候，该节点会发送一个PSYNC命令给master，如果这是slave的重新连接，master仅仅会发送给slave部分缺少的数据进行<strong>增量复制</strong>，如果这是slave第一次连接master，会触发一次<strong>全量复制</strong>。</p>
<p>官方解释：</p>
<ol>
<li>slave启动时，仅仅保存master的host和ip（redis.conf中配置的），此时复制流程还没开始。</li>
<li>slave内部有个定时任务，每秒都会check是否有新的master要连接和复制，如果发现则建立网络连接。</li>
<li>slave发送ping给master，如果master配置了requirepass，那么slave必须发送masterauth口令过去认证。</li>
<li>master第一次执行全量复制，将所有数据发送给slave。</li>
<li>master后续还会持续将写命令异步发送给slave。</li>
</ol>
<p>全量复制：开始full resynchronized的时候，master会启动一个后台线程，生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕以后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着master会将内存中缓存的写命令发送给slave，slave来同步这些数据。</p>
<p>增量复制：master根据slave发送的psync中的offset，在backlog中查找到部分丢失的数据，发送给slave。</p>
<h4 id="主从复制的断点续传"><a href="#主从复制的断点续传" class="headerlink" title="主从复制的断点续传"></a>主从复制的断点续传</h4><p>从redis2.8开始就支持主从复制的断点续传了。在主从复制过程中，如果网络连接断掉了，可以接着上次复制的地方继续复制，而不是重新开始复制。master会在内存中维护一个backlog，master和slave都会保存一个复制数据的replica offset和一个master run id，offset就是保存在backlog中的。如果master和slave网络中断了，slave会让master从上次的replica offset开始继续复制。但是如果没有找到对应的offset，那么就会执行一次resynchronized。</p>
<p>官方解释：</p>
<ol>
<li>master和slave都会维护一个offset，slave每秒都会上报自己的offect给master，master记录在backlog中，这样才能知道双方数据是否一致。</li>
<li>master还会维护一个backlog文件，默认是1M大小，给slave复制数据时也会记录在backlog中，主要是用来做全量复制中断后的增量复制的。</li>
<li>master重启或者加载了之前的RDB数据是会变的，run id也会变，所以slave需要根据不同的run id区分，如果run id不同就需要做全量复制。</li>
<li>从节点使用psync从master进行复制，发送psync runid offset到master。master会根据自身的情况返回相应的信息，可能是FULLRESYNC runid offset触发全量复制，也可能是CONTINUE触发增量复制。</li>
</ol>
<h4 id="无磁盘化复制"><a href="#无磁盘化复制" class="headerlink" title="无磁盘化复制"></a>无磁盘化复制</h4><p>在redis的配置文件中开启无磁盘化复制以后，master会在内存中直接创建rdb文件然后发送给slave，不会保存在本地磁盘。这里不建议开启，开启也很简单，主要涉及到两个参数：repl-diskless-sync no 默认是no，改成yes就可以了，repl-diskless-sync-delay 5 默认是延迟5s在开始复制，因为需要等待更多的slave重新连接。</p>
<h4 id="过期key处理"><a href="#过期key处理" class="headerlink" title="过期key处理"></a>过期key处理</h4><p>slave不会过期key，只会等待master过期key。</p>
<p>如果master过期了一个key，或者通过LRU淘汰了一个key，master会模拟一条del命令发送给slave。</p>
<h4 id="redis的心跳检测机制"><a href="#redis的心跳检测机制" class="headerlink" title="redis的心跳检测机制"></a>redis的心跳检测机制</h4><p>在命令传播阶段，slave每隔一秒向master发送一个心跳，主要用来检测双方的网络连接状态。</p>
<h4 id="redis的持久化"><a href="#redis的持久化" class="headerlink" title="redis的持久化"></a>redis的持久化</h4><p>如果采用了主从架构，建议必须开启master node的持久化。</p>
<p>不建议用slave node作为master node的热备，因为那样的话如果关掉master的持久化（RDB和AOF都关闭）可能在master宕机重启的时候数据是空的，然后从节点一复制，slave node的数据也丢了。</p>
<p>即使slave node可以自动接管master node，也可能哨兵还没有检测到master failure，master node就重启了，还是可能导致上面的所有slave node数据被清空的故障。</p>
<p><strong>持久化方式RDB和AOF</strong></p>
<ul>
<li>RDB持久化机制：通过快照的方式，对redis中的数据进行周期性的持久化。</li>
<li>AOF持久化机制：通过记录写命令，以append-only模式写入到日志文件中，redis重启时重新构建。</li>
</ul>
<p>如果同时开启了RDB和AOF两种持久化机制，在redis重启时会使用AOF来构建数据，因为AOF数据更加完整。</p>
<p>如果我们想要redis仅仅作为纯内存的缓存来用，可以关掉RDB和AOF持久化机制。</p>
<p><strong>RDB的优点</strong></p>
<ol>
<li>RDB会生成多个数据文件，非常适合做冷备，可以上传到云盘定期维护。</li>
<li>RDB对redis的性能影响非常小，定期把数据写入到磁盘，使redis保持高性能。</li>
<li>通过RDB数据文件来做数据恢复更加快速，直接把文件加载到内存即可。</li>
</ol>
<p><strong>RDB的缺点</strong></p>
<ol>
<li>最大的缺点就是可能造成部分数据丢失。由于RDB是定期备份，可能每隔5分钟甚至更久，如果redis突然宕机，可能会丢失部分数据，所以RDB不适合作为第一优先的恢复方案。</li>
<li>RDB每次执行快照生成数据文件的时候，如果数据文件特别大，可能会导致redis对客户提供的服务暂停数秒，所以不要让RDB备份的间隔太长，否则每次生成的文件太大，影响redis本身的性能。</li>
</ol>
<p><strong>AOF的优点</strong></p>
<ol>
<li>AOF可以更好的保护数据不丢失，一般AOF会每隔一秒记录一次，所以最多丢失1秒的数据。</li>
<li>AOF日志以append-only模式写入，没有磁盘寻址开销，写入性能高，且文件不易破损。</li>
<li>AOF日志文件过大的时候，出现后台重写操作也不会影响reids客户端的读写效率。</li>
<li>AOF特别合适误删除的紧急恢复，比如输入了flushall清空了数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall删除，然后再将AOF文件放回去，就可以自动恢复。</li>
</ol>
<p><strong>AOF的缺点</strong></p>
<ol>
<li>最大的缺点就是做数据恢复的时候会比较慢，做冷备和定期备份不方便，需要手写复杂脚本。</li>
<li>对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。</li>
<li>AOF开启后，支持的QPS会比RDB低，因为每秒一次fsync，不过性能还是很高的。</li>
<li>如果想保证一条数据都不丢，也是可以的，设置成每写入一条数据就fsync一次，不过性能会大降。</li>
<li>AOF相比于RDB更加脆弱一些，恢复数据后可能导致跟原来不一样，容易产生bug。</li>
</ol>
<p><strong>RDB和AOF到底如何选择</strong></p>
<ul>
<li>不要仅仅使用RDB，因为那样会导致丢失很多数据。</li>
<li>也不要仅仅使用AOF，因为AOF不适合做冷备，恢复数据比较慢还容易产生bug。</li>
<li>所以综合使用AOF和RDB两种持久化机制，用AOF保证数据不丢失，作为数据恢复的第一选择；用RDB来做不同程度的冷备，在AOF文件都丢失或者损坏不可用的时候，还可以使用RDB快照来进行数据恢复。</li>
</ul>
<hr>
<h3 id="redis的哨兵机制"><a href="#redis的哨兵机制" class="headerlink" title="redis的哨兵机制"></a>redis的哨兵机制</h3><p>sentinal，中文名是哨兵，是redis集群架构中非常重要的一个组件，主要功能如下：</p>
<ol>
<li>集群监控：负责监控redis master和slave进程是否正常工作。</li>
<li>消息通知：如果某个redis实例有故障，哨兵负责发送消息给管理员报警。</li>
<li>故障转移：如果master挂掉了，会自动转移到slave上。</li>
<li>配置中心：如果故障转移发生了，把新的master地址通知到客户端。</li>
</ol>
<p>哨兵本身也是分布式的，作为一个哨兵集群在运行，互相协同工作。</p>
<ol>
<li>故障转移时，判断一个master是否宕机，需要大部分的哨兵同意才行，涉及到分布式选举。</li>
<li>即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，保证了系统的高可用性。</li>
</ol>
<h4 id="哨兵的核心知识"><a href="#哨兵的核心知识" class="headerlink" title="哨兵的核心知识"></a>哨兵的核心知识</h4><ol>
<li>哨兵至少需要3个实例，来保证自己的健壮性。</li>
<li>哨兵+redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用。</li>
<li>对于哨兵+redis主从的复杂架构，尽量在测试和生产环境都进行充足的测试和演练。</li>
</ol>
<p><strong>为什么redis哨兵集群少于3个节点无法正常工作</strong></p>
<p>如果哨兵集群只有两个节点，两个哨兵的majority=2，其中master所在的机器宕机了，这时只剩下一个哨兵，哨兵切换故障需要满足大多数哨兵同意原则，此时没有majority来运行执行故障转移，所以两个哨兵节点不能工作。</p>
<h4 id="sdown和odown转换机制？"><a href="#sdown和odown转换机制？" class="headerlink" title="sdown和odown转换机制？"></a>sdown和odown转换机制？</h4><p>master宕机有sdown和odown两种失败状态</p>
<ul>
<li>sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，就是主观宕机。</li>
<li>odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，就是客观宕机。</li>
<li>sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-after-milliseconds指定的毫秒数之后，就主观认为master宕机了</li>
<li>sdown到odown的转换条件也很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，也就是客观认为master宕机。</li>
</ul>
<h4 id="哨兵和slave集群的自动发现机制"><a href="#哨兵和slave集群的自动发现机制" class="headerlink" title="哨兵和slave集群的自动发现机制"></a>哨兵和slave集群的自动发现机制</h4><p>哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往_sentinel_:hello channel里发送一个消息，内容是自己的host、ip和runid，还有对这个master的监控配置。每个哨兵也会去监听自己监控的master+slave对应的_sentinel_:hello channel，然后去感到到同样在监听这个master+slave的其他哨兵的存在，每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步。</p>
<h4 id="slave-master选举算法"><a href="#slave-master选举算法" class="headerlink" title="slave-master选举算法"></a>slave-master选举算法</h4><p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来准备升级为master。</p>
<p><strong>从节点过滤</strong>：判断跟master断开连接的时长</p>
<p>如果一个slave跟master断开连接已经超过了（down-after-milliseconds的10倍+master宕机的时长），那么slave就被认为不适合选举为master。</p>
<ol>
<li>slave配置的优先级（slave-priority=100）</li>
<li>复制offset</li>
<li>run id</li>
</ol>
<p>说明：</p>
<ol>
<li>然后把剩下了的slave按照优先级进行排序，slave priority越低，优先级就越高。</li>
<li>如果slave priority相同，就看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高。</li>
<li>如果上面两个条件都相同，那么选择一个run id比较小的那个slave。</li>
</ol>
<h4 id="slave配置的自动纠正"><a href="#slave配置的自动纠正" class="headerlink" title="slave配置的自动纠正"></a>slave配置的自动纠正</h4><p>哨兵会自动纠正slave的配置信息。比如某台slave要成为潜在的master候选人，哨兵会确保slave在复制现有的master数据；如果slave连接到了一个错误的master上，比如故障转移后，哨兵会确保它们连接到正确的master上。</p>
<h4 id="quorum和majority"><a href="#quorum和majority" class="headerlink" title="quorum和majority"></a>quorum和majority</h4><p>每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还要得到majority哨兵的授权，才能正式执行切换。</p>
<p>如果quorum &lt; majority，比如5个哨兵，majority就是3，quorum设置为2，可以执行切换。</p>
<p>如果quorum &gt;= majority，比如5个哨兵，设置quorum是5，那么必须5个哨兵都授权才能切换。</p>
<h4 id="configuration-epoch"><a href="#configuration-epoch" class="headerlink" title="configuration epoch"></a>configuration epoch</h4><p>哨兵进行切换之前，执行切换的那个哨兵从要切换到新的master那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的。如果第一次master切换失败了，那么其他哨兵会等待failover-timeout时间，然后继续执行切换，此时会重新获得一个新的configuration epoch，作为新的version号。</p>
<h4 id="configuration传播"><a href="#configuration传播" class="headerlink" title="configuration传播"></a>configuration传播</h4><p>哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他哨兵，通过pub/sub消息机制。</p>
<p>这里version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的，其他的哨兵都是根据版本号的大小来更新自己的master配置。</p>
<hr>
<h2 id="异步复制和集群脑裂导致数据丢失"><a href="#异步复制和集群脑裂导致数据丢失" class="headerlink" title="异步复制和集群脑裂导致数据丢失"></a>异步复制和集群脑裂导致数据丢失</h2><p>场景一：异步复制导致的数据丢失</p>
<p>client往redis master写入数据，master还没来得及复制给slave，此时，master宕机了，哨兵检测到master宕机后，从slave中投票选举出新的master，但是没来得及复制的数据就丢失了。</p>
<p>场景二：集群脑裂导致的数据丢失</p>
<p>master出现了网络异常，与其他slave节点失去联系，但没有挂掉，其他slave节点上的哨兵机制重新选举了master，不过此时的client跟旧的master网络是好的，发送了数据到旧的master数据没有得到同步，此时检测到该master有问题，修好网络后作为slave挂在到新的master节点上，但是新的master没有同步网络异常时的数据导致丢失。</p>
<p><strong>如何降低损失？</strong></p>
<ul>
<li>min-slaves-to-write 1</li>
<li>min-slaves-max-lag 10</li>
</ul>
<p>配置说明：要求至少有一个slave，数据复制和同步的延迟不能超过10秒。也就是说一旦所有的slave数据的复制和同步都超过了10秒，这时master就不会再接收写请求了，可以把数据落差保持在可控范围内，减少数据损失。</p>
<p>上述配置也适合脑裂，master发生脑裂以后，所有slave都不向旧的master发送数据，10秒之后旧master停止接收写请求，同样也可以减少脑裂带来的数据丢失。</p>
<hr>
<h2 id="分布式集群-redis-cluster"><a href="#分布式集群-redis-cluster" class="headerlink" title="分布式集群-redis cluster"></a>分布式集群-redis cluster</h2><ol>
<li>自动将数据进行分片，每个master上放一部分数据。</li>
<li>提供内置的高可用支持，部分master不可用时，还是可以继续工作的。</li>
</ol>
<p>redis cluster可以突破单机redis在海量数据面前的瓶颈。</p>
<p><strong>redis cluster VS replication+sentinal</strong></p>
<p>如果数据量很少，只有几个G，主要是承载高并发性能的场景，那么单机足够了。采用主从架构，再搭建一个sentinal集群，保证高可用。如果你的数据量很大，建议使用redis cluster。</p>
<h3 id="分布式数据存储的核心算法"><a href="#分布式数据存储的核心算法" class="headerlink" title="分布式数据存储的核心算法"></a>分布式数据存储的核心算法</h3><h4 id="最老土的hash算法和弊端"><a href="#最老土的hash算法和弊端" class="headerlink" title="最老土的hash算法和弊端"></a>最老土的hash算法和弊端</h4><p>把请求的数据进行hash运算，对hash值取模（针对master数量）然后放入对应的master节点中，如果某台master宕机了，该节点中的缓存数据就会失效，更严重的是由于master数量少了，导致取模方式改变，新的请求通过取模运算后得不到有效缓存，会造成几乎100%的请求涌入数据库重新生成缓存，这里会涉及到<strong>大量的缓存重建</strong>，这是致命的。</p>
<h4 id="一致性hash算法-自动缓存迁移"><a href="#一致性hash算法-自动缓存迁移" class="headerlink" title="一致性hash算法(自动缓存迁移)"></a>一致性hash算法(自动缓存迁移)</h4><p>有请求过来以后，同样是把key进行hash运算，然后会把hash值对应在圆环的各个点上，key落在圆环上以后就会顺时针旋转去寻找距离自己最近的master节点，如果任何一个master节点宕机，只有在该master上的缓存会失效，比如有3台master节点，宕机一台，1/3的数据流量会瞬间涌入数据库，重新查询一次，在环上的master节点越多，宕机后失效的数据越少。这只是均匀分布的情况，如有区间存在缓存热点，还是会有弊端。</p>
<h4 id="一致性hash算法-虚拟节点"><a href="#一致性hash算法-虚拟节点" class="headerlink" title="一致性hash算法+虚拟节点"></a>一致性hash算法+虚拟节点</h4><p>基于一致性hash算法，在各个master节点之间，再创建均匀分布的虚拟节点，在每个区间内，大量的数据都会均匀的分布到不同的节点，不会存在大量的缓存顺时针同时融入一个master内，实现了自动的<strong>负载均衡</strong>。</p>
<h4 id="hash-slot算法"><a href="#hash-slot算法" class="headerlink" title="hash slot算法"></a>hash slot算法</h4><p>redis cluster有固定的16384个哈希槽，对每个key计算CRC16的值，然后对16384取模，注意不是对机器取模，所以即使有任何一台机器宕机，其他master中的缓存是不受影响的，经过短暂的数据迁移后，会把宕机中的缓存数据均匀分布到其他的master中继续提供服务。而且master slot让node的增加和移除变得很简单，只需要针对机器的个数均匀分配16384个哈希槽就可以了。</p>
<hr>
<h3 id="redis集群模式的工作原理"><a href="#redis集群模式的工作原理" class="headerlink" title="redis集群模式的工作原理"></a>redis集群模式的工作原理</h3><h4 id="节点间的内部通信机制"><a href="#节点间的内部通信机制" class="headerlink" title="节点间的内部通信机制"></a>节点间的内部通信机制</h4><p><strong>基础通信原理</strong></p>
<p>redis cluster节点间采用<strong>gossip</strong>协议进行通信。</p>
<p>跟集中式不同，不是将元数据（节点信息、故障等）集中存储在某个节点上，而是互相之间不断通信，保持整个集群所有节点的数据是完整的。</p>
<ul>
<li>集中式：好处在于，元数据的更新和读取的时效性非常好，一旦有变更，其他节点立刻就能感知到。缺点是所有的元数据的更新全部集中在一个地方，可能导致元数据的存储压力。</li>
<li>gossip：好处在于，元数据的更新比较分散，更新请求会陆陆续续的打到所有节点上去更新，降低了压力。缺点是元数据的更新有一定的延迟，可能导致集群的一些操作滞后。</li>
</ul>
<p>10000端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口，每个节点每隔一段时间都会往另外几个节点发送ping信息，收到后返回pong。通过通信端口结合gossip协议相互交换信息，包括故障信息、节点的增加和删除、hash slot信息等等。</p>
<p><strong>gossip协议</strong></p>
<p>gossip协议包含多种消息，包括ping、pong、meet、fail等。</p>
<ul>
<li>meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始和其他节点进行通信。</li>
<li>ping：每个节点都会频繁的给其他节点发送ping，其中包含自己的状态还有自己维护集群的元数据，互相通过ping进行元数据的交换和更新。</li>
<li>pong：返回ping和meet，包含自己的状态和其他信息，也可以用于广播和更新。</li>
<li>fail：某个节点判断另一个节点fail后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。</li>
</ul>
<p><strong>ping消息深入</strong></p>
<p>每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点。如果发现某个节点通信延时达到了cluster_node_timeout，就会立即发送ping，避免数据交换延迟过长。所以cluster_node_timeout可以调节，如果调节比较大，就可以降低发送的频率。每次ping需要带上自己的节点信息，还有就是带上1/10的其他节点信息，发送出去，进行数据交换。至少包含3个其他节点的信息，最多包含（总节点-2）个其他节点信息。</p>
<hr>
<p>jedis的运行原理：重定向，计算hash slot，采用smart jedis，在本地维护了一个hash slot -&gt; node的映射表缓存。</p>
<h4 id="高性能与主备切换原理"><a href="#高性能与主备切换原理" class="headerlink" title="高性能与主备切换原理"></a>高性能与主备切换原理</h4><p>redis cluster的高可用原理，几乎和哨兵是一样的。</p>
<ol>
<li><p>判断节点宕机</p>
<p>如果一个节点认为另外一个节点宕机了，就是pfail，主观宕机。如果多个节点都认为另外一个节点pfail了，那么就是客观宕机fail。节点之间把pfail放在gossip ping中进行通信，超过半数认为pfail就是fail。</p>
</li>
<li><p>从节点过滤</p>
<p>对于宕机的master，从其所有的从节点slave中选择一个切换成master，检查每个slave与宕机的master断开连接的时间，如果超过了（cluster-node-timeout * cluster-slave-validity-factor）将失去选举资格。</p>
</li>
<li><p>master选举</p>
<p>每个从节点都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多），选举时间越靠前，优先进行选举。然后开始进行投票，具体过程和哨兵类似，选举通过成为新的master。</p>
</li>
</ol>
<p>综上所述：redis cluster功能强大，直接集成了replication和sentinal的功能。</p>
<hr>
<h2 id="缓存雪崩、缓存穿透、缓存击穿"><a href="#缓存雪崩、缓存穿透、缓存击穿" class="headerlink" title="缓存雪崩、缓存穿透、缓存击穿"></a>缓存雪崩、缓存穿透、缓存击穿</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>定义：指在某一时间段，缓存集体失效。</p>
<h4 id="造成缓存雪崩的原因"><a href="#造成缓存雪崩的原因" class="headerlink" title="造成缓存雪崩的原因"></a>造成缓存雪崩的原因</h4><ol>
<li>比如双11零点抢购，大量商品被集中放入到缓存，假设缓存时效为一小时，那么到了凌晨1点的时候缓存就集体失效了，大量的请求会打在数据库上，对数据库来说，就会产生周期性的压力波峰，可能造成缓存雪崩。</li>
<li>缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。</li>
</ol>
<h4 id="如何预防缓存雪崩？"><a href="#如何预防缓存雪崩？" class="headerlink" title="如何预防缓存雪崩？"></a>如何预防缓存雪崩？</h4><p>针对缓存集体失效：如果是电商项目，一般是采取不同分类商品，缓存不同周期。在同一分类中的商品，加上一个随机因子。这样能尽可能分散缓存过期时间，而且，热门类目的商品缓存时间长一些，冷门类目的商品缓存时间短一些，也能节省缓存服务的资源。</p>
<p>针对缓存服务器宕机：redis高可用（主从+哨兵 或者 redis cluster），避免全盘奔溃。</p>
<h4 id="缓存雪崩了如何恢复？"><a href="#缓存雪崩了如何恢复？" class="headerlink" title="缓存雪崩了如何恢复？"></a>缓存雪崩了如何恢复？</h4><p>本地ehcache缓存+hystrix限流&amp;降级，避免mysql被打死。事后通过redis持久化快速恢复缓存数据。</p>
<hr>
<h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>定义：是指查询一个数据库一定不存在的数据，请求穿过了缓存，直接打在了数据库。</p>
<h4 id="造成缓存穿透的原因"><a href="#造成缓存穿透的原因" class="headerlink" title="造成缓存穿透的原因"></a>造成缓存穿透的原因</h4><p>代码bug或者恶意攻击。</p>
<h4 id="如何预防缓存穿透？"><a href="#如何预防缓存穿透？" class="headerlink" title="如何预防缓存穿透？"></a>如何预防缓存穿透？</h4><p>如果从数据库查询的对象为空，也放入缓存，只是设定的缓存过期时间较短，比如设置为60秒。</p>
<hr>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>定义：是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。</p>
<h3 id="如何预防缓存击穿？"><a href="#如何预防缓存击穿？" class="headerlink" title="如何预防缓存击穿？"></a>如何预防缓存击穿？</h3><p>这种情况遇到的比较少，真有这种爆款key，设置成永不过期就可以了。</p>
<hr>
<h2 id="如何保证缓存与数据库的双写一致性"><a href="#如何保证缓存与数据库的双写一致性" class="headerlink" title="如何保证缓存与数据库的双写一致性"></a>如何保证缓存与数据库的双写一致性</h2><h3 id="先删缓存，再更新数据库"><a href="#先删缓存，再更新数据库" class="headerlink" title="先删缓存，再更新数据库"></a>先删缓存，再更新数据库</h3><p>最经典的缓存+数据库读写的模式：暂存模式（cache aside pattern）</p>
<ol>
<li>读的时候先读缓存，缓存没有的话就读数据库，然后把数据库的数据放到缓存，同时返回相应。</li>
<li>更新的时候，<strong>先删除缓存，再更新数据库</strong>，如果修改数据库失败了，那么数据库中是旧数据，缓存中是空的，不会造成不一致，因为读的时候缓存中没有，还会把旧的数据库数据更新到缓存中。反过来，如果先更改数据库再删除缓存，如果缓存删除失败了，则会导致数据不一致。</li>
</ol>
<p>为什么是删除缓存，而不是更新缓存呢？</p>
<p>原因很简单，很多时候复杂点的缓存场景，不单单是修改了一个值那么简单，而是需要结合多张表去计算才能得到缓存结果，就算真的是简单场景的缓存，也需要看看这个缓存是不是被频繁的使用到，否则只是增加麻烦而已。</p>
<p>其实删除缓存就是一个lazy计算的思想，不需要每次都做复杂的运算，它被用到的时候再计算就好了。</p>
<hr>
<h3 id="高并发场景下的数据不一致"><a href="#高并发场景下的数据不一致" class="headerlink" title="高并发场景下的数据不一致"></a>高并发场景下的数据不一致</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没有修改，一个请求过来，去读缓存，发现缓存空了，去查询数据库，把旧的数据放到了缓存中，然后数据库完成了修改，此时数据库和缓存的数据不一致了。</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>把数据库与缓存的更新读取操作进行异步串行化。</p>
<ul>
<li>更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个内存队列中。</li>
<li>读取数据的时候，如果发现数据不在缓存中，那么将进行（重新读取+更新缓存）操作，也根据唯一标识路由并发送到同一个内存队列中。</li>
</ul>
<p>一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。</p>
<p>这样的话，一个数据变更的操作，先删除缓存，然后去更新数据库，但是还没有完成更新；此时如果一个读请求过来，读到了空的缓存，可以先将缓存更新的请求发送到队列中积压，然后同步等待缓存更新完成。</p>
<p>这里有一个优化点，一个队列中，多个读请求（更新缓存）串在一起是没有意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，就不用再放更新操作进入队列了，直接等待前面的缓存更新完成即可。如果请求还在等待范围内，不断轮询发现可以取到值了就返回，超过等待时长就返回数据库中的旧值。</p>
<h4 id="解决方案需要注意的问题"><a href="#解决方案需要注意的问题" class="headerlink" title="解决方案需要注意的问题"></a>解决方案需要注意的问题</h4><p><strong>读请求 长时间堵塞</strong></p>
<p>由于读请求做了非常轻度的异步化，所以一定要注意读超时问题，每个读请求必须在超时时间范围内返回。</p>
<p>该方案的最大风险在于可能数据更新很频繁，或者包含了对多个数据项的修改，导致队列中积压了大量的更新操作在里面，然后读请求发生了大量的超时，最后导致大量的读请求直接走数据库。一定要提前做好压力测试和真实数据模拟，不过一般来说数据的写频率是很低的，所以队列中积压的应该不会太多。如果真的导致积压过多的话，可以采取增加内存队列的方式来解决。</p>
<p><strong>读请求 并发量过高</strong></p>
<p>上述方案有可能突然大量的读请求在几十毫秒内hang在服务器上，看需要几台服务器才能扛得住，所以要计算好每个读请求不要hang太久。</p>
<p><strong>多服务实例部署的请求路由</strong></p>
<p>可能这个服务部署了多个实例，那么必须保证，执行数据更新操作以及执行缓存更新操作的请求，都通过nginx服务器路由到相同的服务器实例上。</p>
<p><strong>热点商品的路由问题</strong></p>
<p>万一某个商品的读写请求特别高，全部打到相同的机器的相同队列里去了，可能造成某台机器的压力过大。</p>
<p>因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题影响不是很大，不过的缺可能某些机器的负载高一些。</p>
<hr>
<h2 id="如何保证redis并发竞争的数据一致性"><a href="#如何保证redis并发竞争的数据一致性" class="headerlink" title="如何保证redis并发竞争的数据一致性"></a>如何保证redis并发竞争的数据一致性</h2><p>客户端角度：为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。</p>
<p>服务器角度：采用分布式锁，确保同一时刻只能有一个系统实例在操作某个key，获得分布式锁以后，每次要写之前，先判断当前这个value的时间戳是否比缓存中的时间戳更新，如果更新，可以写入；否则，就不能用旧数据覆盖新数据。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">lishaojie</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://lishaojie1993.github.io/2019/03/12/redis/">https://lishaojie1993.github.io/2019/03/12/redis/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/分布式/">分布式</a><a class="post-meta__tags" href="/tags/redis/">redis</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://i.loli.net/2020/01/07/GWbsNc9tgwDVIPa.png"><div class="post-qr-code__desc">支付宝赞赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="https://i.loli.net/2020/01/07/r9DjGqAuBXtM2wQ.png"><div class="post-qr-code__desc">微信赞赏</div></div></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/03/15/volatile/"><i class="fa fa-chevron-left">  </i><span>volatile关键字解析</span></a></div><div class="next-post pull-right"><a href="/2019/03/11/Thread-Pool/"><span>线程池实现原理与源码分析</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><a href="https://item.taobao.com/item.htm?spm=a1z10.1-c.w137644-18883948773.38.556e5eff3UmbVU&id=599185802394"><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gaq6j5fhawj30t809qdvk.jpg" width="99%" height="33%"></a></div><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'https://lishaojie1993.github.io/2019/03/12/redis/';
  this.page.identifier = '2019/03/12/redis/';
  this.page.title = '分布式缓存-Redis';
}
var d = document, s = d.createElement('script');
s.src = "https://" + 'lishaojie1993-blog' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script><script id="dsq-count-scr" src="https://lishaojie1993-blog.disqus.com/count.js" async></script></div></div><footer class="footer-bg" style="background-image: url(https://tva1.sinaimg.cn/large/006tNbRwgy1gash4k2x0uj31900u0b1g.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2020 By lishaojie</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>